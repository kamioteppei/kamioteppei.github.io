<!DOCTYPE html>
<html lang="ja">
<head prefix:og="http://ogp.me/ns#">
  <meta charset="UTF-8">
  <title>Machine Learning | kamioteppei.github.io</title>
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700">
  <!-- Default CSS -->
  <link rel="stylesheet" href="/assets/css/style.css">
  <meta name="viewport" content="width=device-width">
  <meta name="description" content="機械学習">
  <link rel="canonical" href="http://0.0.0.0:4000/memos/machine-learning">
  <link type="application/atom+xml" rel="alternate" href="http://0.0.0.0:4000/feed.xml" title="kamioteppei.github.io" />
  
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      displayAlign: "left",
      displayIndent: "2em"
    });
  </script>
  <script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
  <script language="JavaScript">
    $(document).ready( function () {
       $("a[href^='http']:not([href*='" + location.hostname + "'])").attr('target', '_blank');
    })
  </script>
</head>
<body>

<header class="header">
  <nav id="nav" class="nav">
    <div class="container nav__container">
      <div class="nav__brand"><a class="nav__title" href="/">kamioteppei.github.io</a></div>
      <div id="nav__btn" class="nav__btn"><i class="fa fa-bars"></i></div>
      <ul id="nav__list" class="nav__list">
        
          <li class="nav__item"><a href="/">Home</a></li>
        
        
          
            <li class="nav__item"><a href="/stack/">Stack</a></li>
          
        
          
            <li class="nav__item"><a href="/blog/">Blog</a></li>
          
        
          
            <li class="nav__item"><a href="/links/">Links</a></li>
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</header>











<div class="contents page">

  
    <div class="container">

      <!--
      <div class="page__header">
  <h1 class="page__title">Machine Learning</h1>
  
  
    <p class="page__date">February 02, 2019</p>
  
</div>

    -->

      <div class="page__body">
        <div class="row">

          <div class="col-2 sidebar order-xs-first">
            <nav id="jqxTree" class="jqxTree">
  <!--
  https://www.siteleaf.com/blog/advanced-liquid-group-by/
  -->
  
  <ul>
    
      <li class="">
        Native
        <ul>
        
          <li class="">
            <div class=""><a href="/memos/android">Android</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/ios">iOS</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/vr">VR/AR</a></div>
          </li>
        
        </ul>
    </li>
    
      <li class="">
        Environment
        <ul>
        
          <li class="">
            <div class=""><a href="/memos/aws">AWS</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/ci">CI/CD</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/docker">Docker</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/elasticsearch">Elasticsearch</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/gcp">GCP</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/git">Git</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/heroku">Heroku</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/mac">Mac</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/package-management">Package Manager</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/ssh">SSH</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/ubuntu">Ubuntu</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/vagrant">Vagrant</a></div>
          </li>
        
        </ul>
    </li>
    
      <li class="">
        UI/UX
        <ul>
        
          <li class="">
            <div class=""><a href="/memos/bootstrap">Bootstrap</a></div>
          </li>
        
        </ul>
    </li>
    
      <li class="">
        Engineer
        <ul>
        
          <li class="">
            <div class=""><a href="/memos/career">Career</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/freelance">Freelance</a></div>
          </li>
        
        </ul>
    </li>
    
      <li class="">
        Machine Learning
        <ul>
        
          <li class="">
            <div class=""><a href="/memos/competition">Competition</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/data">Data</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/jupyter-notebook">Jupyter Notebook</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/machine-learning">Machine Learning</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/math">Math</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/nlp">Natural language processing</a></div>
          </li>
        
        </ul>
    </li>
    
      <li class="">
        Web
        <ul>
        
          <li class="">
            <div class=""><a href="/memos/http">HTTP</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/jekyll">Jekyll</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/markdown">Markdown</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/rails">Rails</a></div>
          </li>
        
          <li class="">
            <div class=""><a href="/memos/security">Security</a></div>
          </li>
        
        </ul>
    </li>
    
  </ul>
</nav>

          </div>

          <div class="col-8 main toc-src order-first">
            <h1 id="機械学習">機械学習</h1>

<h2 id="サービスの構成">サービスの構成</h2>

<p>以下を参照</p>

<p><a href="https://employment.en-japan.com/engineerhub/entry/2017/11/30/110000">［37選］機械学習ライブラリやフレームワークは？ 国内AI活用サービスのアーキテクチャを大調査！</a></p>

<h2 id="機械学習の問題解決プロセス">機械学習の問題解決プロセス</h2>
<ul>
  <li>課題設定(課題発見)</li>
  <li>データ収集
    <ul>
      <li>データセットダウンロード</li>
      <li>WebAPIでダウンロード</li>
      <li>Webスクレイピング</li>
      <li>ラベリングの作業が大変</li>
      <li>画像は180度反転させたデータを作成するなどデータの増やし方がある。(その方が過学習を防げる)</li>
    </ul>
  </li>
  <li>データクリーニング
    <ul>
      <li>画像のデータサイズの統一化</li>
      <li>Null値の補正</li>
    </ul>
  </li>
  <li>データ相関確認
    <ul>
      <li>正の相関</li>
      <li>負の相関</li>
      <li>相関のある項目がなかったら？</li>
    </ul>
  </li>
  <li>モデル開発
    <ul>
      <li>自前開発</li>
      <li>転移学習</li>
    </ul>
  </li>
  <li>モデルチューニング</li>
  <li>データ可視化</li>
</ul>

<h2 id="機械学習の学習方法の分類">機械学習の学習方法の分類</h2>
<ul>
  <li>教師あり学習</li>
  <li>教師なし学習</li>
  <li>強化学習(報酬あり学習)</li>
</ul>

<h2 id="機械学習の問題解決方法の分類">機械学習の問題解決方法の分類</h2>
<ul>
  <li>回帰(Regression)<br />
データの集合を関数で抽象化(微分)して、時系列データを予測する。<br />
関数と集合の誤差が最小になるようにする。</li>
  <li>クラス分類(Classification)
    <ul>
      <li>パターン認識<br />
データのクラスごとの集合を分ける境界線を引く。<br />
境界線とクラスごとの集合までのマージンが最大になるようにする。</li>
      <li>文字認識<br />
画像のピクセルの集合をベクトルに変換して、畳み込みにより抽象化する。</li>
    </ul>
  </li>
  <li>グループ分け、クラスタリング(Clustering)<br />
 ラベルのないデータを、何らかの特徴で分類する。</li>
  <li>推薦(Recommendation)</li>
</ul>

<h2 id="モデル">モデル</h2>

<h3 id="線形回帰">線形回帰</h3>
<p>直線の式を求める。式に含む係数を割り出す。</p>

<h3 id="非線形回帰">非線形回帰</h3>
<p>直線ではない式を求める。</p>

<h3 id="回帰">回帰</h3>
<ul>
  <li>単回帰 -&gt; １つの変数と切片(bias)の１次関数、微分する。</li>
  <li>多項式回帰 -&gt; 1つの変数について、次数が複数ある。偏微分する。</li>
  <li>重回帰 -&gt; 変数が２つ以上、偏微分する。</li>
</ul>

<p><a href="http://tkengo.github.io/blog/2016/06/02/yaruo-machine-learning3/">多項式回帰と重回帰</a></p>

<h3 id="ロジスティック回帰">ロジスティック回帰</h3>
<p>データを確率的に分類する。</p>
<ul>
  <li>2値分類 -&gt; dog or cat</li>
  <li>多値分類 -&gt; mnist 0~9の画像を分類</li>
</ul>

<h3 id="k近傍法">k近傍法</h3>
<p>k=3とした場合、任意のテストデータに最も近いk個の教師データのラベルを抽出し、<br />
そのラベルの多数決や平均から、ラベルを判定する。</p>

<h3 id="svmsupport-vector-machine">SVM(Support Vector Machine)</h3>
<p>データを分ける境界線を引く。<br />
境界線とデータまでのマージンが最大になるようにする。</p>

<h3 id="random-forest-randomized-trees">Random Forest, Randomized Trees</h3>
<p>学習用データから多数の決定木を作成し、作成した決定木を元に、<br />
多数決で結果を決める。</p>

<h3 id="neural-network">Neural Network</h3>
<p>生物の脳の神経細胞をモデルとしたアルゴリズム。<br />
以下の層を持つ。</p>
<ul>
  <li>S層(感覚層、入力層) <br />
画像を入力する場合、画像が28x28ビクセルなら、積の784個のニューロンを作成する。 <br />
入力値xは手書き文字の濃さによって0~255等の範囲をとる。また、演算効率を上げるため、入力値を255(最大値)で除算して0.00~1.00のfloat型に変換する(正規化)と良い。 <br />
カラーの画像だと、入力のベクトル因子が3つに増える。(RGBの3つ)</li>
  <li>A層(連合層、中間層、隠れ層)</li>
  <li>R層(反応層、出力層) <br />
画像の分類を出力する場合、入力した画像のラベルが0~9なら、10個のニューロンを作成する。(出力値は各分類値の出現確率で、合計すると1になる。)
出力層では、恒等関数を使用し、入力値をそのまま出力する。</li>
</ul>

<p>隠れ層が多いモデルを、Deep Learningと呼ぶ。<br />
以前は隠れ層は2,3層だったが、最近は数十層に及ぶ。</p>

<p>入力層と出力層のみの2層からなる、単純パーセプトロン (Simple perceptron) は線形非分離な問題を解けなかった。<br />
パーセプトロンを多層にし、バックプロパゲーション（誤差逆伝播学習法）で学習させることで、線型分離不可能な問題が解けるように、
単純パーセプトロンの限界を克服した。</p>

<h2 id="deep-learning">Deep Learning</h2>
<p>多層構造のニューラルネットワークを用いた機械学習のこと。
結果から、重みを自分で調節できることが一番重要だと思う。</p>

<ul>
  <li>Weight -&gt; inputに対する調整値</li>
  <li>bias -&gt; 次の中間層に対する調整値</li>
</ul>

<p>TensorFlow公式の<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.60237&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false">ニューラルネットワークのデモ</a>を見るとなんとなくイメージがわく。</p>

<h3 id="cnnconvolution-neural-network">CNN(Convolution Neural Network)</h3>
<p>画像認識に用いられるニューラルネットワークモデル。<br />
隠れ層を「畳み込み層」と「プーリング層」で構成する。</p>

<ul>
  <li>
    <p>畳み込み層 <br />
例）<br />
チャンネル(C)が1(=モノクロ、カラーならC=3)、縦横(HxW)が32x32の画像を入力とし、その外縁を1周り0パティングする。
それに対して、縦横(HxW)5x5のフィルターを、1づつスライドさせると、
縦横(HxW)が30x30の畳み込み画像ができる。フィルターは、5x5の重みの行列とし、そのフィルターの数を10とする。
すると、10枚の畳み込みデータが作成される。フィルターの重み(画像の個々の特徴)は自動で抽出される。<br />
5x5のフィルターに、画像を判断する手がかり(特徴)が収まれば学習が進む。例えば、数字の4を読み込んだ時に、鋭角のフィルターを２つと、
十時のフィルターを抽出できれば、画像の判定時に、その3つのフィルターに当てはまる文字は4と判定できる。
フィルターのことをカーネルともいう。</p>
  </li>
  <li>
    <p>プーリング層 <br />
例）<br />
縦横(HxW)が32x32の画像を16x16に圧縮する。
max poolingがよく使われる。実装としては、2x2の領域ごとに、最大値を抽出する。
それにより、細かい画像の特徴のブレ(振動)が補正される。</p>
  </li>
  <li>
    <p>全結合層<br />
Fully Connected層(fc層)<br />
通常のLinearレイヤー。<br />
プーリング層の出力値を1次元の配列で受け取り、線形回帰する。
最後の出力層でソフトマックス関数で、クラス分類を行う。</p>
  </li>
</ul>

<p><a href="https://products.sint.co.jp/aisia/blog/vol1-16#toc-1">参照</a></p>

<h4 id="dcgan">DCGAN</h4>
<p>Deep Convolutional Generative Adversarial Networks <br />
(敵対生成ネットワーク)</p>

<ul>
  <li>Generator(生成器) <br />
Generatorが作成した画像をfake、inputデータの画像をrealと、Discriminator(識別器)が正しく判定する確率を最小化するように画像を生成する。
逆にいうと、Discriminator(識別器)を誤らせる(騙す)確率を最大化する。</li>
  <li>Discriminator(識別器) <br />
Generatorが作成した画像をfake、inputデータの画像をrealと、自分が正しく判定する確率を最大化する。</li>
</ul>

<h3 id="rnnrecurrent-neural-network">RNN(Recurrent Neural Network)</h3>
<p>隠れ層に戻り値があるニューラルネットワークモデル。<br />
音声の波形、動画、文章などの時系列データを扱う。</p>

<ul>
  <li>Embedding層というトークン(単語)をベクトル化した層</li>
  <li>LSTM(Long Short Term Memory)という隠れ層を使用する。
    <ul>
      <li>Input Gate</li>
      <li>Output Gate</li>
      <li>Forget Gate</li>
    </ul>
  </li>
</ul>

<p><a href="https://qiita.com/KojiOhki/items/89cd7b69a8a6239d67ca">参照1</a><br />
<a href="https://qiita.com/t_Signull/items/21b82be280b46f467d1b">参照2</a></p>

<p>CNNは、モデルで定義した通りの層の数だが、RNNは例えば、文章を入力すると、単語の数だけ、再帰的に、
層の数が増えるので、最も汎用性が高いと思われる。</p>

<h3 id="resnet">ResNet</h3>
<p>学習対象（レイヤーごとの仮説関数）に入力の差（残差）を使うことで、勾配消失問題（層が深くなるにつれて、勾配が0に収束してしまう問題）を解消するディープラーニング。</p>

<h3 id="dqndeep-q-network">DQN（Deep Q-Network）</h3>
<p>強化学習において、行動価値関数Q(s,a)（sの状態の時にaという行動をとる価値を）の値が高くなる様に学習する方法をQ学習といい、Q学習をパラメータを追加した近似関数とて表し、ディープラーニングで求める手法。</p>

<h3 id="ナイーブベイズ分類">ナイーブベイズ分類</h3>
<p>スパムメールの判別に使用する。<br />
訓練データの文章が、スパムメールであれば、スパムメールの辞書に、単語と出現回数を登録する。
スパムメールでなければ、非スパムメールの辞書に、単語と出現回数を登録する。
テストでは、読み込んだ文章の単語ごとに、スパムメール辞書と非スパムメール辞書での出現確率を合計し、
確率の高い方を正と判定する。</p>

<h2 id="framework">Framework</h2>

<h3 id="scikit-learn">scikit-learn</h3>
<p>以下のSVMを提供するパッケージ</p>
<ul>
  <li>SVC(処理速度より正確性をとる場合)</li>
  <li>LinearSVC(正確性より処理速度をとる場合)</li>
</ul>

<h3 id="tensorflow">TensorFlow</h3>
<p>Google社製<br />
deeplearningできる。</p>

<h3 id="keras">keras</h3>
<p>TensorFlowのラッパー<br />
記述を簡単にできる</p>

<h3 id="pytorch">PyTorch</h3>
<p>Facebook社製<br />
deeplearningできる。 <br />
chainerからforkされた。</p>

<h2 id="モデルの部品">モデルの部品</h2>

<h3 id="活性化関数activation">活性化関数(Activation)</h3>
<ul>
  <li>Step(Formal neuron(形式ニューロン), Threshold Logic Unit )
    <ul>
      <li>ヘヴィサイドの階段関数を使い、入出力の値は 0 または 1 の二値だけをとる。</li>
      <li>入力値の合計が閾値を超えた場合、1を返し、閾値未満の場合は、0を返す。それ以外は0.5を返す。</li>
      <li>ヘヴィサイドの階段関数 -&gt; <code class="highlighter-rouge">function H(x) = if x&lt;0 then 0 else if x&gt;0 then 1 else 1/2 </code></li>
      <li>AND回路 -&gt; <code class="highlighter-rouge">function AND(x1,x2) = H(x1 + x2 - 1.5) </code></li>
      <li>OR回路 -&gt; <code class="highlighter-rouge">function OR(x1,x2) = H(x1 + x2 - 0.5) </code></li>
      <li>NOT回路 -&gt; <code class="highlighter-rouge">function NOT(x) = H(-x + 0.5) </code></li>
      <li>XOR回路 -&gt; <code class="highlighter-rouge">function XOR(x1,x2) = H(x1 + x2 -2H(x1 + x2 -1.5) - 0.5) </code></li>
    </ul>
  </li>
  <li>Sigmoid
    <ul>
      <li>入力値を、0から1の値に収束する。</li>
      <li>ネイピア数 -&gt; <code class="highlighter-rouge">constant e = 2.71828182845904...</code></li>
      <li>Sigmoid関数 -&gt; <code class="highlighter-rouge">function Sigmoid(x) = 1 / (1 + e^-x )</code></li>
    </ul>
  </li>
  <li>tanh(Sigmoid関数を線形変換したもの)
    <ul>
      <li>入力値を、-1から1の値に収束する。</li>
    </ul>
  </li>
  <li>ReLU (Rectified Linear Unit,正規化線形関数) (推奨)<br />
<code class="highlighter-rouge">function ReLU(x) = max(0,x)</code>-&gt; <code class="highlighter-rouge">if x&lt;=0 then return 0 else return x</code></li>
  <li>Linear</li>
  <li>Softmax
    <ul>
      <li>入力値を、0から1の値に収束する。</li>
      <li>ディープラーニングの出力層で使用される。</li>
      <li>イメージ図<br />
<a href="https://qiita.com/rtok/items/b1affc619d826eea61fd">参照</a>
        <blockquote>
          <p>「softmax関数は多くの次元からなる入力のうち、自分の値が他の値たちに比べて一番目立っているならば、その値が1
に近づく関数である」といえます。</p>
        </blockquote>
      </li>
    </ul>
  </li>
</ul>

<h3 id="正則化regularization">正則化(Regularization)</h3>
<p>正則化はモデルのパラメータの学習に使われ、特に過学習を防ぎ、汎化能力を高めるために使われる。</p>

<ul>
  <li>L1正則化(LASSO) <br />
L1ノルム(記号：||x||1)・・・ベクトルの各要素の絶対値を合計したもの</li>
  <li>L2正則化(Ridge) <br />
L2ノルム(記号：||x||2)・・・ベクトルの各要素を２乗を合計したものの平方根</li>
  <li>Elastic Net Regression</li>
</ul>

<p><a href="https://rindalog.blogspot.com/2017/07/regularizationridgelasso-elastic-net.html">参照</a></p>
<blockquote>
  <p>相関関係にある独立変数がデータセットにあるとする。Elastic Net は相関関係にある変数のグループを作る。グループの変数の一つが強い予測子（依存変数と強い相関関係にある）の場合、グループの変数をモデルに含める。（Lasso のように）他の変数を除くのは、データの理解に必要な情報の欠落で、モデル性能を落とすことに繋がりかねない。</p>
</blockquote>

<h3 id="誤差逆伝播法">誤差逆伝播法</h3>
<ul>
  <li>ニューラルネットの重みなどのパラメータ決定を勾配法で行う。</li>
  <li>勾配法の計算の際に損失関数の微分を行う。</li>
  <li>誤差逆伝播法を用いると計算が順伝播に比べて、高速にできる。
    <ul>
      <li>順伝播<br />
全レイヤーの重みとバイアスのニューロンの数が全部で10個だとすると、その10個をループして、
<script type="math/tex">\frac{f(x_0 + \Delta x_0 , x_1 , ... , x_9) - f(x_0 , x_1 , ... , x_9)}{\Delta x_0}</script> ,
<script type="math/tex">\frac{f(x_0, x_1 + \Delta x_1 , ... , x_9) - f(x_0 , x_1 , ... , x_9)}{\Delta x_1}</script> … と <br />
ニューラルネットワークの走査を10 * 2回も行わなくてはならない。<br />
(10個のノードで、微分前後の出力値の差分を誤差として算出し、集計する。)</li>
      <li>逆伝播<br />
後ろからニューロンの数だけ、計算すれば良いらしい。</li>
    </ul>
  </li>
</ul>

<p>単語</p>
<ul>
  <li>計算グラフ = Computational graph</li>
  <li>誤差逆伝播法 = Back propagation</li>
  <li>自動微分 = Automatic differentiation</li>
</ul>

<p><a href="http://yusuke-ujitoko.hatenablog.com/entry/2016/12/31/230118">参照</a></p>

<ul>
  <li>
    <p>偏微分 <br />
複数の変数による関数があるとして、その中の1つの変数のみに関する微分のこと</p>
  </li>
  <li>
    <p>forwardとbackward <br />
trainingの時は、誤差のbackward処理が必要だが、testの時は、不要となるので、設定を変更する。</p>
  </li>
</ul>

<h3 id="dropout">Dropout</h3>
<p>全ての訓練データを使用すると、過学習する(局所解に捕まる)場合があるので、<br />
パラメータで指定した割合のデータをランダムでカットする。</p>

<p>確率的勾配降下法(Stochastic Gradient Descent, SGD)の実装は、Dropoutのことか、<br />
それとも、ミニバッチ方式のことなのか、要調査。</p>

<ul>
  <li>Dropout<br />
任意のレイヤーのノードに対する入力をマスクする確率を指定する。<br />
疑問：２個のノードのある中間層に0.5を指定した場合どうなる？
    <ul>
      <li>必ずどちらかのノードが無効になる</li>
      <li>各ノードが50%の確率で無効になる。2つとも同時に無効になることは？</li>
      <li>各ノードの入力が、50%カットされる。</li>
    </ul>
  </li>
</ul>

<p>答えは、１番だと思われる。デメリットとして、異なるネットワークの定義を使用している(=アンサンブル)ことになるので、
その分、収束に時間がかかる。</p>

<ul>
  <li>Batch Normalization
    <ul>
      <li>入力データのノイズを柔らげる</li>
      <li>L2正則化の必要性が下がる</li>
      <li>Dropoutの必要性が下がる</li>
    </ul>
  </li>
</ul>

<p><a href="https://qiita.com/cfiken/items/88427533ea9b501a6c10">参照1</a> <br />
<a href="https://qiita.com/cfiken/items/b477c7878828ebdb0387">参照2</a></p>

<h3 id="損失関数誤差関数">損失関数/誤差関数</h3>
<ul>
  <li>
    <p>二乗誤差 <br />
線形回帰で使用する。</p>
  </li>
  <li>
    <p>交差(クロス)エントロピー誤差</p>
    <ul>
      <li>2クラス分類用の数式</li>
      <li>多クラス分類用の数式</li>
    </ul>
  </li>
</ul>

<p><a href="https://mathwords.net/kousaentropy">参照</a></p>

<h2 id="検証validation">検証(Validation)</h2>

<h3 id="クロスバリデーション">クロスバリデーション</h3>
<p>学習データのサンプリングの偏りによる、<br />
過学習を防ぐために、学習データとテストデータを、 <br />
ローテーションして学習する手法。</p>

<h3 id="グリッドサーチ">グリッドサーチ</h3>
<p>モデルに渡すパラメータを自動で、色々試す手法。</p>


          </div>

          <div class="col-2 sidebar order-xs-first">
            <nav class="toc"></nav>

          </div>

        </div><!--row-->
      </div><!--page-body-->

    </div><!--container-->

  

</div><!--page-->



<footer class="footer">
  
  <div class="container container--sm footer__container">
  
    <p class="copyright"><small>&copy; 2018 kamioteppei</small></p>

    <div class="social-link">
      
        <p class="social-link__item">
          <a href="https://github.com/kamioteppei"><i class="fa fa-github"></i></a>
        </p>
      
      
    </div>
  </div><!--container-->
</footer>

<script src="/assets/js/jfgp.js"></script>
</body>
</html>
