---
layout: static
title: Math
template: 3-columns
name: Math
category: Machine Learning
---

# Math

## 指数関数

指数関数って何の為？

[参照](https://math.nakaken88.com/textbook/introduction-exponent-logarithm-magnitude/)
>ここで見たきたように、指数関数・対数関数を学ぶことで、大きすぎる数字や小さすぎる数字を扱ったり、比較・計算することが易しくなったりします。

  ネイピア数 e≒2.718 を x乗した数 $$ e^x $$ を $$ \exp x $$ と表記する。  
  expはexponent(指数)の略。  

## 対数関数

対数関数って何の為？

[参照](https://math.nakaken88.com/textbook/basic-logarithm/)
>さて、この計算をよく見てみましょう。計算が行われているメインの場所はどこでしょうか。それは、2の右上の部分、指数の部分、ですね。分数で表して、通分して…、という計算を行っています。
>
しかし、文字の大きさでいうと、すごく小さいですね。小さい文字でちまちまと分数の計算をするのは大変です。しかも、2の部分は、「2のなんとか乗」で表した後は、計算上、あまり重要じゃないですね。2行目以降、ずっと変わりません。
>
こうしてみると、この計算で大きく取り上げたいのは指数の部分で、2の部分（底）はそんなに大きく取り上げる必要はないですね。このように、指数の部分に注目したいという場合に使えるのが、対数(logarithm) というものです。

- 対数関数

  底がaの対数関数。  
  「a(低数)を何乗したら x(真数)になるか」= 指数を表す

  $$ \log_a x $$

  例えば「2(低数)を何乗したら 8(真数)になるか」を表す式は、

  $$ \log_2 8 $$

  であり、「2を3乗したら 8になる」ので答えは以下となる。

  $$ \log_2 8 = 3 $$

  logのない世界に戻ると以下になる。

  $$ 2^3 = 8 $$

  「 2 を底とする 8 の対数は、3 である」

- 常用対数   
  10を底とする対数。  
  桁数を表す時によく使う。

  $$ \log_{10} x $$ を $$ \log x $$ と表記する。

- 自然対数(ネーピア対数)    
  ネーピア数を底とする対数。  

    $$ \log_e x $$ を $$ \ln x $$ と表記する。


## 微分/偏微分

- differentiate 【動詞】 ～を微分する
- derivative 【名詞】導関数、微分係数
- partial derivative 【名詞】偏微分

### 微分
変数は1つ=単回帰

単語の用法(個人的まとめ)

- 関数y=f(x)を微分して、導関数f'(x)を求めた時、f'(a)とすれば、f(x)のx=aにおける微分係数(=接線の傾き)が求まる。
- 関数y=f(x)の微分は、f'(x)であり、f'(a)とすれば、f(x)のx=aにおける微分係数(=接線の傾き)が求まる。

$$ f'(x) = \frac{dy}{dx} = \lim_{\Delta x \to 0} \frac{f(x+\Delta x)-f(x)}{\Delta x} $$

### 偏微分
変数は2つ以上=重回帰

単語の用法(個人的まとめ)

- 関数z=f(x,y)をxについて偏微分して、偏導関数 $$ f_x(x,y) $$ を求めた時、変数xのみの関数z=g(x)の偏導関数g'(a)に置き換えられるので、、g(x)のx=aにおける偏微分係数(=接線の傾き)が求まる。
- 関数z=f(x,y)のxについての偏微分 $$ f_x(x,y) $$ は、変数xのみの関数z=g(x)の偏導関数g'(a)に置き換えられるので、、g(x)のx=aにおける偏微分係数(=接線の傾き)が求まる。

- xに対する偏微分  

$$ f_x(x,y) = \frac{\delta z}{\delta x} = \lim_{\Delta x \to 0} \frac{f(x+\Delta x,y)-f(x,y)}{\Delta x} $$

- yに対する偏微分   

$$ f_y(x,y) = \frac{\delta z}{\delta y} = \lim_{\Delta y \to 0} \frac{f(x,y+\Delta y)-f(x,y)}{\Delta y} $$

**メモ**   
偏微分は1つの変数のみに対する計算と思いきや、そうではなく、微分の式で、変化させる変数が1つということ。
だから、xに対する微分では、分子で、xのみが微増した時の $$ f(x+\Delta x,y) $$ から、何も微増しない $$ f(x,y) $$ を引いている。

### 連鎖律

合成関数の導関数がそれぞれの導関数の積の形で与えられることを、連鎖律(chain rule)という。   
y=f(u)および、u=g(x)の時、y=f(g(x))となり、この合成関数の導関数は、次の式となる。

$$
\frac{dy}{dx} = \frac{dy}{du} ・ \frac{du}{dx} \\ \;\;\;\;\;\;
 = f'(g(x)) ・ g'(x)
$$

### その他

#### 微分する時に、 $$ \Delta x $$ を0に近ずける理由  
[参照](https://math.nakaken88.com/textbook/basic-derivative-function/)

y=f(x)が1次関数であれば、2点(x, y(x)),($$ x + \Delta x , y(x + \Delta x ) $$ が決まれば
その直線(=接線)の傾きが決まり、どのxにおいても傾きは同じなので、どのxにおいての増減もわかる。(増減の変化率は一定)   
1次関数には極小点はないが、機械学習のロス関数の話でいえば、おそらく、y=0のxが分かれば、それで良いような気がする。

2次関数以上は、2点が決まっても、その間が大きいと、その間に、山や谷があり得るので、傾きを一般化できない。
変化量の $$ \Delta x $$ を0に近ずければ、f(x)のx=aにおける接線になるので、そこでの傾きがわかる。
ただし、全てのxでの傾きを調べる必要はなく、導関数は、元の式の増減を表す式だから、導関数y=f'(x)のy=0のxが、
増減の変化率=0、つまり、山の頂点か、谷の底だとわかる。

ここら辺を理解する為に、極限値や増減表や、グラフの書き方を学習したいと思う。

### 理解できていないこと

二乗誤差平均を最小化したいことは分かる。微分・偏微分の単体の考え方も分かる。だが、この2つが繋がらない。


## 線形代数/ベクトル


## 確率


## Tensor(テンソル)
以下全て、tensorの1種

### scalar(スカラー)
0次元
- 1
- 10.5
- -100

### vector(ベクター)
1次元

横ベクトル、行ベクトル、row vector
- [1,4,10]

縦ベクトル、列ベクトル、column vector
- [  
1,  
5,  
9  
]  

### matrix,matrices(行列)
2次元

`metrics`という単語が、ディープラーニングのモデルのパラメータに、  
出てくるが、 **評価基準** という意味で別物。


### tensor(テンソル)
行列の行列
